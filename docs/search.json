[{"path":"index.html","id":"preamble","chapter":"1 Preamble","heading":"1 Preamble","text":"manual aims providing training implementation genomics-enabled decision support NextGen Cassava Breeding Project community practice partnerships.Associated manual provide codebase standard operating procedures reproducible BreedBase-integrated workflow.Two major sections currently planned:Genomic (Mate) Selection Workflow Example: Using example dataset Cassavabase, work hands-, demos, full workflow. Provide skeleton pipeline segment: purpose, SOP, checklist, template, necessary inputs, KPI outputs.Genomic (Mate) Selection Workflow Example: Using example dataset Cassavabase, work hands-, demos, full workflow. Provide skeleton pipeline segment: purpose, SOP, checklist, template, necessary inputs, KPI outputs.Data wrangling reproducibility: Intro hands-computing data environment / manipulation side things. Learning resources/links. excel! R, Tidyverse, functions, loops, bash / command line, genomic data manipulation programs.Data wrangling reproducibility: Intro hands-computing data environment / manipulation side things. Learning resources/links. excel! R, Tidyverse, functions, loops, bash / command line, genomic data manipulation programs.Collectively two components support learning Genomic prediction selection: practice.Genomic prediction selection: theoryStudents also may need/want learn statistical quantitative genetic theory. additional section planned , minimum provide guidance access reading learning resources. starters, (Lynch Walsh 1998; Falconer FALCONER 2003; Isik et al. 2017; Bernardo 2020)!","code":""},{"path":"outline.html","id":"outline","chapter":"2 Outline","heading":"2 Outline","text":"Create project repositoryDownload training data: Download training data using BreedBase, including: phenotypes, genotypes, pedigreeQC format field trial data.","code":""},{"path":"using-this-manual.html","id":"using-this-manual","chapter":"3 Using this manual","heading":"3 Using this manual","text":"","code":""},{"path":"using-this-manual.html","id":"workflow-notes","chapter":"3 Using this manual","heading":"3.1 Workflow notes","text":"Create workflowR repository genomic prediction analysis, following instructions .Create workflowR repository genomic prediction analysis, following instructions .Follow along following documents templates examples:\nGenomic Selection Manual (BOOK)\nGS Process Map (~LINKED , SHOWN THROUGHOUT MANUAL~)\nGS Checklist (~LINKED ~)\nFollow along following documents templates examples:Genomic Selection Manual (BOOK)GS Process Map (~LINKED , SHOWN THROUGHOUT MANUAL~)GS Checklist (~LINKED ~)Use variant documents code examples complete genomic prediction analysis develop report results.Use variant documents code examples complete genomic prediction analysis develop report results.Advice best practices:\nChoose data, traits, cassavabase\nWork example code actually .\nFollow-functions don’t know going manual.\nstrive provide references tutorials, papers, etc. give context help learn detail desired..\n\nInevitably, want divergences, alterations, bells--whistles top process documented. SUGGEST altering developing process maps checklists go.\nUse combination Rmarkdown (.Rmd) Rscripts (.R) document analysis, demonstrated.\nTake time write commentary throughout. full sentences, intend ? interpret results? next step? Etc.\nTake time think naming datasets, files, folders, R objects, etc.\nUse Git version control, made easy Rstudio.\nPublish code GitHub report results webpage using GitHub Pages. demonstrate using package workflowR manage aspects.\nAdvice best practices:Choose data, traits, cassavabaseChoose data, traits, cassavabaseWork example code actually .\nFollow-functions don’t know going manual.\nstrive provide references tutorials, papers, etc. give context help learn detail desired..\nWork example code actually .Follow-functions don’t know going manual.strive provide references tutorials, papers, etc. give context help learn detail desired..Inevitably, want divergences, alterations, bells--whistles top process documented. SUGGEST altering developing process maps checklists go.Inevitably, want divergences, alterations, bells--whistles top process documented. SUGGEST altering developing process maps checklists go.Use combination Rmarkdown (.Rmd) Rscripts (.R) document analysis, demonstrated.Use combination Rmarkdown (.Rmd) Rscripts (.R) document analysis, demonstrated.Take time write commentary throughout. full sentences, intend ? interpret results? next step? Etc.Take time write commentary throughout. full sentences, intend ? interpret results? next step? Etc.Take time think naming datasets, files, folders, R objects, etc.Take time think naming datasets, files, folders, R objects, etc.Use Git version control, made easy Rstudio.Use Git version control, made easy Rstudio.Publish code GitHub report results webpage using GitHub Pages. demonstrate using package workflowR manage aspects.Publish code GitHub report results webpage using GitHub Pages. demonstrate using package workflowR manage aspects.","code":""},{"path":"using-this-manual.html","id":"r-sessions-packages-to-load","chapter":"3 Using this manual","heading":"3.2 R sessions, packages to load","text":"use tidyverse also genomicMateSelectR packages throughout pipeline.others may appear.recommend, pipeline segment, starting new R session. Begin segment, step load R packages:","code":"\nlibrary(tidyverse)\nlibrary(genomicMateSelectR)\nlibrary(gt) # just for the nice looking tables"},{"path":"using-this-manual.html","id":"software-to-install","chapter":"3 Using this manual","heading":"3.3 Software to install","text":"RRRstudioRstudioPackages\ntidyverse\ngenomicMateSelectR\nPackagestidyversegenomicMateSelectRBioinformatics tools\nvcftools\nbcftools\nBioinformatics toolsvcftoolsbcftools","code":""},{"path":"using-this-manual.html","id":"high-performance-and-remote-computing","chapter":"3 Using this manual","heading":"3.4 High performance and remote computing","text":"","code":""},{"path":"create_project.html","id":"create_project","chapter":"4 Create a project","heading":"4 Create a project","text":"","code":""},{"path":"create_project.html","id":"create-a-workflowr-project","chapter":"4 Create a project","heading":"4.1 Create a workflowR project","text":"","code":""},{"path":"create_project.html","id":"using-rmarkdown","chapter":"4 Create a project","heading":"4.2 Using Rmarkdown","text":"","code":""},{"path":"create_project.html","id":"code-chunks","chapter":"4 Create a project","heading":"4.2.1 Code chunks","text":"","code":""},{"path":"create_project.html","id":"hotkeys","chapter":"4 Create a project","heading":"4.3 Hotkeys","text":"CMD+Option+= create chunkShift+CMD+M = %>% pipe operator","code":""},{"path":"create_project.html","id":"tidyverse-functions","chapter":"4 Create a project","heading":"4.4 Tidyverse functions","text":"","code":""},{"path":"create_project.html","id":"using-git","chapter":"4 Create a project","heading":"4.5 Using Git","text":"","code":""},{"path":"create_project.html","id":"publishing-on-github-pages","chapter":"4 Create a project","heading":"4.6 Publishing on GitHub (Pages)","text":"","code":""},{"path":"create_project.html","id":"project-organization-recommendations","chapter":"4 Create a project","heading":"4.7 Project Organization Recommendations","text":"","code":""},{"path":"download-training-data.html","id":"download-training-data","chapter":"5 Download training data","heading":"5 Download training data","text":"Go Cassavabase favorite alternative BreedBase.Login.Go Search > Wizard","code":""},{"path":"download-training-data.html","id":"example-dataset","chapter":"5 Download training data","heading":"5.1 Example dataset","text":"sake example, choose small, real dataset think exemplify data stored DB. , choose data key features, including pedigree relationship high-proportion genotyped accessions.","code":""},{"path":"download-training-data.html","id":"create-trial-list","chapter":"5 Download training data","heading":"5.1.1 Create trial list","text":"Create list trials using “Wizard”IITA trials Ibadan Ubiaja locations, planted 2019. chose key trial types specific trials seen screenshot.Create list: IITA_ExampleGStrials_2021Dec04","code":""},{"path":"download-training-data.html","id":"download-related-trial-data","chapter":"5 Download training data","heading":"5.1.2 Download related trial data","text":"Clear Wizard panesStart new list trials created: “IITA_ExampleGStrials_2021Dec04”Download “Related Trial Metadata” “Related Trial Phenotypes”Exports .csv files phenotype.csv metadata.csv.Store data/ sub-directory current project.","code":""},{"path":"download-training-data.html","id":"make-an-accession-list","chapter":"5 Download training data","heading":"5.1.3 Make an accession list","text":"\\[NEW + EXPTL\\] Choose:Genotyping Protocol: “IITA DArT-GBS 08 Aug 2021,” thenAccessions: “Select ”Create list “IITA_ExampleGSaccessions_2021Dec05”.","code":""},{"path":"download-training-data.html","id":"validate-lists","chapter":"5 Download training data","heading":"5.1.4 Validate lists","text":"stage, validate lists created avoid problems downloading. critical step opportunity also correct things database.Click “Lists” top navigation bar.Find accession list created.Click list name “IITA_ExampleGSaccessions_2021Dec05” case.Click “Validate” button. waiting period.list fails, guidance provided problem. Correct possible. Seek assistance database administrator others necessary.example, list fail validation.100% know consequences following two choices, :Choose “Replace synonyms corresponding DB name” “List elements matching synonym.”\nbutton didn’t seem anything permanent.\nChoose “Replace synonyms corresponding DB name” “List elements matching synonym.”button didn’t seem anything permanent.decided manually delete three accessions: “Kaleso” “W940102” lastly “ANKRA”.decided manually delete three accessions: “Kaleso” “W940102” lastly “ANKRA”., recheck list passes validation close pop-., recheck list passes validation close pop-.Emphasis aspect requiring attention collaboration data generators / managers!!!","code":""},{"path":"download-training-data.html","id":"download-related-trial-genotype-data","chapter":"5 Download training data","heading":"5.1.5 Download related trial genotype data","text":"Download “Related Trial Genotype Data,” choosing available formats: VCF Dosage Matrix (.tsv).NOTE: probably take usually times . However, Cassavabase complete preparation file even disconnect ready--go return, ready, begin downloading immediately.NOTE ALSO downloads range 700Mb (VCF) 150Mb (Dosage TSV).","code":""},{"path":"download-training-data.html","id":"download-pedigree","chapter":"5 Download training data","heading":"5.1.6 Download Pedigree","text":"Go “Manage > Download > Download Pedigree”","code":""},{"path":"prepare-phenotype-data.html","id":"prepare-phenotype-data","chapter":"6 Prepare phenotype data","heading":"6 Prepare phenotype data","text":"Context Purpose: step, quality control, clean format training data analysis.Upstream: Section 5 - training data downloadDownstream: pretty much everythingInputs: “Raw” field trial dataExpected outputs: “Cleaned” field trial data","code":""},{"path":"prepare-phenotype-data.html","id":"read-db-data","chapter":"6 Prepare phenotype data","heading":"6.1 Read DB data","text":"Load phenotype metadata downloads R.built function readDBdata simply wraps around read.csv, reads merges metadata plot-basis data. metadataFile= argument can left NULL.HINT: point manual, reference use custom function genomicMateSelectR, encourage check reference page function, e.g. readDBdata(). look code typing e.g. readDBdata R console heading GitHub repo.","code":"\ndbdata<-readDBdata(phenotypeFile = here::here(\"data\",\"phenotype.csv\"),\n                   metadataFile = here::here(\"data\",\"metadata.csv\"))\n#> Joining, by = c(\"studyYear\", \"programDbId\", \"programName\", \"programDescription\", \"studyDbId\", \"studyName\", \"studyDescription\", \"studyDesign\", \"plotWidth\", \"plotLength\", \"fieldSize\", \"fieldTrialIsPlannedToBeGenotyped\", \"fieldTrialIsPlannedToCross\", \"plantingDate\", \"harvestDate\", \"locationDbId\", \"locationName\")"},{"path":"prepare-phenotype-data.html","id":"detect_designs","chapter":"6 Prepare phenotype data","heading":"6.2 Check experimental designs","text":"Checklist: data plot-basis, plant-basis mixture? plant-basis data present, converted plot-basis analysis?plot-basis case.Checklist: experimental designs present? represented variables dataset? designs consistent expectations, example relative reported “trialType,” “studyName” /“studyDesign?”step, past, certain experimental designs trials downloaded. also certain designs represented column-names. reason, developed ad hoc custom code “detect” designs. built genomicMateSelectR function detectExptDesigns(). See example .RECOMMENDATION: analyst needs use exploratory data anlaysis, making summary statistics plots necessary determine data modelled downstream. missing incorrectly represented trial design variables, get corrected database (contact breeding program data manager, necessary).small example dataset, possible look 9 trials evaluate.Often, many trials part genomic prediction. essential trial designs consistent, clear analyst. may need derive strategy similar detectExptDesigns() function semi-automate process.Summary table shows:trialType studyDesign 100% relied upon, least .trial actually listed studyDesign==\"Augmented\" “check” vs. “test” distinguished “entryType.”trialType==\"Clonal Evaluation\" studyDesign==\"RCBD\" actually 1 replication.Next, ’ll check replicate blockNumber columns reliably distinguish complete incomplete blocks data., notice except 1 trial (19.GS.C1.C2.C3.AYT.42.UB) number reps blocks.question , complete replications experiment indicated replicate incomplete sub-blocks represented blockNumberSo 1 trial, 3 complete blocks, sub-blocks. 6 trials, 2 complete replications nested sub-blocks represented blockNumber variable. 2 trials, incomplete blocks.Next, decided check replicate column definitely means complete blocks. might look bit complicated, basically merge two summaries: (1) overall number accessions per trial, (2) average number accessions per replicate per trial.numbers similar trials, indicating complete blocks.One : look min, mean max number accessions per blockNumber., can see except studyName==\"19.GS.C1.C2.C3.AYT.42.UB\" sub-blocks represented blockNumber subsets total number accessions trial, expected., except studyName==\"19geneticgainUB\" trials pretty consistently sized sub-blocks.Now ad hoc create two variables (CompleteBlocks IncompleteBlocks), indicating (TRUE/FALSE) whether model using replicate /blockNumber variable.also like create explicitly nested design variables (yearInLoc, trialInLocYr, repInTrial, blockInRep).Just check:","code":"\ndbdata %>% count(observationLevel)\n#>   observationLevel    n\n#> 1             plot 2533\n# table(dbdata$observationLevel)\nlibrary(gt)\ndbdata %>% \n     count(studyName,trialType, studyDesign, numberBlocks,numberReps,entryType) %>% \n     spread(entryType,n) %>% \n     gt()  %>% \n     tab_options(table.font.size = pct(75))\ndbdata %>% \n     group_by(studyName) %>% \n     summarize(N_replicate=length(unique(replicate)),\n               N_blockNumber=length(unique(blockNumber))) %>% \n     gt() %>% tab_options(table.font.size = pct(75))\ndbdata %>% \n     group_by(studyName) %>% \n     summarize(N_replicate=length(unique(replicate)),\n               N_blockNumber=length(unique(blockNumber)),\n               doRepsEqualBlocks=all(replicate==blockNumber)) %>% \n     gt() %>% tab_options(table.font.size = pct(75))\n# the overall number of accessions per trial\ndbdata %>% \n     group_by(studyName) %>% \n     summarize(N_accession=length(unique(germplasmName))) %>% \n     # the average number of accessions per replicate per trial\n     left_join(dbdata %>% \n                    group_by(studyName,replicate) %>% \n                    summarize(N_accession=length(unique(germplasmName))) %>% \n                    group_by(studyName) %>% \n                    summarize(avgAccessionsPerReplicate=ceiling(mean(N_accession)))) %>% \n     gt() %>% tab_options(table.font.size = pct(75))\n#> `summarise()` has grouped output by 'studyName'. You can override using the `.groups` argument.\n#> Joining, by = \"studyName\"\n# the overall number of accessions per trial\ndbdata %>% \n     group_by(studyName) %>% \n     summarize(N_accession=length(unique(germplasmName))) %>% \n     left_join(dbdata %>% \n     group_by(studyName,replicate,blockNumber) %>% \n     summarize(N_accession=length(unique(germplasmName))) %>% ungroup() %>% \n     group_by(studyName) %>% \n     summarize(minAccessionsPerBlock=ceiling(min(N_accession)),\n               avgAccessionsPerBlock=ceiling(mean(N_accession)),\n               maxAccessionsPerBlock=ceiling(max(N_accession)))) %>% \n     gt() %>% tab_options(table.font.size = pct(60))\n#> `summarise()` has grouped output by 'studyName', 'replicate'. You can override using the `.groups` argument.\n#> Joining, by = \"studyName\"\ndbdata %<>% \n     group_by(studyName) %>% \n     summarize(N_replicate=length(unique(replicate)),\n               N_blockNumber=length(unique(blockNumber)),\n               doRepsEqualBlocks=all(replicate==blockNumber)) %>% \n     ungroup() %>% \n     mutate(CompleteBlocks=ifelse(N_replicate>1,TRUE,FALSE),\n            IncompleteBlocks=ifelse(N_blockNumber>1 & !doRepsEqualBlocks,TRUE,FALSE)) %>% \n     left_join(dbdata) %>% \n     mutate(yearInLoc=paste0(programName,\"_\",locationName,\"_\",studyYear),\n            trialInLocYr=paste0(yearInLoc,\"_\",studyName),\n            repInTrial=paste0(trialInLocYr,\"_\",replicate),\n            blockInRep=paste0(repInTrial,\"_\",blockNumber))\n#> Joining, by = \"studyName\"\ndbdata %>% \n     count(studyName,CompleteBlocks,IncompleteBlocks) %>% \n     left_join(dbdata %>% \n                    group_by(studyName) %>% \n                    summarize(nRepInTrial=length(unique(repInTrial)),\n                              nBlockInRep=length(unique(blockInRep)))) %>% \n     gt() %>% tab_options(table.font.size = pct(67))\n#> Joining, by = \"studyName\""},{"path":"prepare-phenotype-data.html","id":"traits-and-trait-abbreviations","chapter":"6 Prepare phenotype data","heading":"6.3 Traits and Trait Abbreviations","text":"Cassavabase downloads use long column-names corresponding full trait-ontology name. convenience, replace names abbreviations, documented . eventual upload analysis results, names need restored ontology terms.also use opportunity subselect traits.Run function renameAndSelectCols() rename columns remove unselected traits.","code":"\ntraitabbrevs<-tribble(~TraitAbbrev,~TraitName,\n        \"CMD1S\",\"cassava.mosaic.disease.severity.1.month.evaluation.CO_334.0000191\",\n        \"CMD3S\",\"cassava.mosaic.disease.severity.3.month.evaluation.CO_334.0000192\",\n        \"CMD6S\",\"cassava.mosaic.disease.severity.6.month.evaluation.CO_334.0000194\",\n        \"DM\",\"dry.matter.content.percentage.CO_334.0000092\",\n        \"RTWT\",\"fresh.storage.root.weight.per.plot.CO_334.0000012\",\n        \"NOHAV\",\"plant.stands.harvested.counting.CO_334.0000010\")\ntraitabbrevs %>% gt()#rmarkdown::paged_table()\ndbdata<-renameAndSelectCols(traitabbrevs,\n                            indata=dbdata,\n                            customColsToKeep = c(\"observationUnitName\",\n                                                 \"CompleteBlocks\",\n                                                 \"IncompleteBlocks\",\n                                                 \"yearInLoc\",\n                                                 \"trialInLocYr\",\n                                                 \"repInTrial\",\"blockInRep\"))\n#> Joining, by = \"TraitName\""},{"path":"prepare-phenotype-data.html","id":"qc-trait-values","chapter":"6 Prepare phenotype data","heading":"6.4 QC Trait Values","text":"point pipeline, check trait values allowable ranges. Different ways approach . Feel free make plots data!database also mechanisms ensure trait values within allowable ranges.Nevertheless, habit, simple ad hoc approach :","code":"\n# comment out the traits not present in this dataset\ndbdata<-dbdata %>% \n     dplyr::mutate(CMD1S=ifelse(CMD1S<1 | CMD1S>5,NA,CMD1S),\n                   CMD3S=ifelse(CMD3S<1 | CMD3S>5,NA,CMD3S),\n                   # CMD6S=ifelse(CMD6S<1 | CMD6S>5,NA,CMD6S), \n                   # CMD9S=ifelse(CMD9S<1 | CMD9S>5,NA,CMD9S),\n                   # CGM=ifelse(CGM<1 | CGM>5,NA,CGM),\n                   # CGMS1=ifelse(CGMS1<1 | CGMS1>5,NA,CGMS1),\n                   # CGMS2=ifelse(CGMS2<1 | CGMS2>5,NA,CGMS2),\n                   DM=ifelse(DM>100 | DM<=0,NA,DM),\n                   RTWT=ifelse(RTWT==0 | NOHAV==0 | is.na(NOHAV),NA,RTWT),\n                   # SHTWT=ifelse(SHTWT==0 | NOHAV==0 | is.na(NOHAV),NA,SHTWT),\n                   # RTNO=ifelse(RTNO==0 | NOHAV==0 | is.na(NOHAV),NA,RTNO),\n                   NOHAV=ifelse(NOHAV==0,NA,NOHAV),\n                   NOHAV=ifelse(NOHAV>42,NA,NOHAV)\n                   # RTNO=ifelse(!RTNO %in% 1:10000,NA,RTNO)\n     )"},{"path":"prepare-phenotype-data.html","id":"post-qc-composite-traits","chapter":"6 Prepare phenotype data","heading":"6.5 Post-QC: composite traits","text":"Now component traits QC’d, ’s time compute composite traits.composite traits, mean traits computed combinations traits.Examples cassava: season-wide mean disease severity, harvest index, fresh root yield.","code":""},{"path":"prepare-phenotype-data.html","id":"season-wide-mean-disease-severity","chapter":"6 Prepare phenotype data","heading":"6.5.1 Season-wide mean disease severity","text":"","code":"\n# [NEW AS OF APRIL 2021]\n## VERSION with vs. without CBSD\n## Impervious to particular timepoints between 1, 3, 6 and 9 scores\n\n# Without CBSD (West Africa)\ndbdata<-dbdata %>% \n  mutate(MCMDS=rowMeans(.[,colnames(.) %in% c(\"CMD1S\",\"CMD3S\",\"CMD6S\",\"CMD9S\")], na.rm = T)) %>% \n  select(-any_of(c(\"CMD1S\",\"CMD3S\",\"CMD6S\",\"CMD9S\")))\n\n# With CBSD (East Africa)\n# dbdata<-dbdata %>% \n#   mutate(MCMDS=rowMeans(.[,colnames(.) %in% c(\"CMD1S\",\"CMD3S\",\"CMD6S\",\"CMD9S\")], na.rm = T),\n#          MCBSDS=rowMeans(.[,colnames(.) %in% c(\"CBSD1S\",\"CBSD3S\",\"CBSD6S\",\"CBSD9S\")], na.rm = T)) %>% \n#   select(-any_of(c(\"CMD1S\",\"CMD3S\",\"CMD6S\",\"CMD9S\",\"CBSD1S\",\"CBSD3S\",\"CBSD6S\",\"CBSD9S\")))"},{"path":"prepare-phenotype-data.html","id":"fresh-root-yield-fyld","chapter":"6 Prepare phenotype data","heading":"6.5.2 Fresh root yield (FYLD)","text":"RTWT (fresh root weight per plot kg) –> FYLD (fresh root yield tons per hectare)\\[FYLD = \\frac{RTWT_{kg / plot}}{MaxHarvestedPlantsPerPlot \\times PlantSpacing}\\times10\\]\nNOTE: MaxHarvestedPlantsPerPlot formula distinguish plantsPerPlot meta-data field, case net-plot harvest used. words, value total number plants intended harvest plot, assuming missing plants plot.PlantSpacing area \\(m^2\\) per plant.example trial data, plantsPerPlot meta-data field empty. knowledge, meta-data field available BreedBase represent net-plot harvest.RECOMMEND INPUTING plantsPerPlot meta-data cassavabase breeding program!Luckily, since 9 trials tutorial, decisions manually.Firstly noting trial 19geneticgainUB actually phenotypes (trait). excluded downstream. (might find substitute genetic gain trial, earlier year, sake example)decide real MaxHarvestedPlantsPerPlot plantsPerPlot likely , make two plots also compute maximum NOHAV trial.sake example, ‘ok’ make choices basis just done.data generator, -house breeding program, reason get correct answer repair metadata database!Additional things compute:log-transform yield traits: habit based experience. Linear mixed-models normally distributed homoskedastic residuals, don’t log-transform response variable often helps. FYLD related traits, always log-transform.Debatable whether better. Let’s dwell . Onward!SUGGESTION: individuals working manual, consider making different, transformations see fit, data. Even better, set-direct comparison results - vs. without-transformation.*","code":"\ndbdata %>% \n     count(studyYear,studyName,studyDesign,plotWidth,plotLength,plantsPerPlot) %>% \n     mutate(plotArea=plotWidth*plotLength) %>% \n     gt() %>% tab_options(table.font.size = pct(67))\ndbdata %>% \n     ggplot(.,aes(x=NOHAV, fill=studyName)) + geom_density(alpha=0.75)\n#> Warning: Removed 921 rows containing non-finite values\n#> (stat_density).\ndbdata %>% \n     # plot area in meters squared\n     mutate(plotArea=plotWidth*plotLength) %>% \n     ggplot(.,aes(x=plotArea,y=NOHAV, fill=studyName)) + \n     geom_boxplot() + theme(axis.text.x = element_blank())\n#> Warning: Removed 921 rows containing non-finite values\n#> (stat_boxplot).\nplantsPerPlot_choices<-dbdata %>% \n     distinct(studyYear,studyName,plotWidth,plotLength,plantsPerPlot) %>% \n     left_join(dbdata %>% \n                    group_by(studyName) %>% \n                    summarize(MaxNOHAV=max(NOHAV, na.rm=T))) %>% \n          # plot area in meters squared\n     mutate(plotArea=plotWidth*plotLength,\n            # Number of plants per plot\n            plantsPerPlot=MaxNOHAV,\n            plantsPerPlot=ifelse(studyName==\"19.GS.C2.UYT.36.setA.UB\",20,plantsPerPlot)) %>% \n     # exclude the empty genetic gain trial\n     filter(studyName!=\"19geneticgainUB\") %>% \n     select(studyName,plotArea,MaxNOHAV,plantsPerPlot)\n#> Warning in max(NOHAV, na.rm = T): no non-missing arguments\n#> to max; returning -Inf\n#> Joining, by = \"studyName\"\nplantsPerPlot_choices %>% gt() #%>% tab_options(table.font.size = pct(67))\ndbdata %<>%\n     # remove the empty genetic gain trial\n     filter(studyName!=\"19geneticgainUB\") %>% \n     select(-plantsPerPlot) %>% \n     # join plantsPerPlot_choices to the trial data\n     left_join(plantsPerPlot_choices) %>% \n     # compute fresh root yield (FYLD) in tons per hectare\n     mutate(PlantSpacing=plotArea/plantsPerPlot,\n            FYLD=RTWT/(plantsPerPlot*PlantSpacing)*10)\n#> Joining, by = \"studyName\"\ndbdata %>% ggplot(.,aes(x=FYLD,fill=studyName)) + geom_density(alpha=0.75)\n#> Warning: Removed 133 rows containing non-finite values\n#> (stat_density).\n# I log transform yield traits \n# to satisfy homoskedastic residuals assumption \n# of linear mixed models\ndbdata %<>% \n     mutate(DYLD=FYLD*(DM/100),\n            logFYLD=log(FYLD),\n            logDYLD=log(DYLD),\n            PropNOHAV=NOHAV/plantsPerPlot) \n# remove non transformed / per-plot (instead of per area) traits\ndbdata %<>% select(-RTWT,-FYLD,-DYLD)\ndbdata %>% ggplot(.,aes(x=logFYLD,fill=studyName)) + geom_density(alpha=0.75)\n#> Warning: Removed 133 rows containing non-finite values\n#> (stat_density)."},{"path":"prepare-phenotype-data.html","id":"save_cleaned_phenos","chapter":"6 Prepare phenotype data","heading":"6.6 Save “cleaned” phenotypes","text":"","code":"\nsaveRDS(dbdata,file=here::here(\"output\",\"phenotypes_cleaned.rds\"))"},{"path":"prepare-genotypic-data.html","id":"prepare-genotypic-data","chapter":"7 Prepare genotypic data","heading":"7 Prepare genotypic data","text":"Context Purpose:\nDepending whether parent- vs. mate-selection intended, several formats --constructed / computed downloaded genotypic data.\nPotentially, exploratory / preliminary assessment population structure, esp. divergence “training” samples selection candidates (“test”).\nContext Purpose:Depending whether parent- vs. mate-selection intended, several formats --constructed / computed downloaded genotypic data.Potentially, exploratory / preliminary assessment population structure, esp. divergence “training” samples selection candidates (“test”).Upstream: Section 6 - quality control steps phenotype dataUpstream: Section 6 - quality control steps phenotype dataDownstream: analyses relying genotypic dataDownstream: analyses relying genotypic dataInputs:\nparent selection: imputed allele-dosage matrix downloaded BreedBase (data/BreedBaseGenotypesDownload.tsv)\nmate selection:\nimputed variant call format (VCF) file downloaded BreedBase (data/BreedBaseGenotypesDownload.vcf)\ncentimorgan-scale genetic map positions reference genome version VCF. Can sourced Cassavabase FTP, FTP archive, another alternative.\n\nInputs:parent selection: imputed allele-dosage matrix downloaded BreedBase (data/BreedBaseGenotypesDownload.tsv)parent selection: imputed allele-dosage matrix downloaded BreedBase (data/BreedBaseGenotypesDownload.tsv)mate selection:\nimputed variant call format (VCF) file downloaded BreedBase (data/BreedBaseGenotypesDownload.vcf)\ncentimorgan-scale genetic map positions reference genome version VCF. Can sourced Cassavabase FTP, FTP archive, another alternative.\nmate selection:imputed variant call format (VCF) file downloaded BreedBase (data/BreedBaseGenotypesDownload.vcf)imputed variant call format (VCF) file downloaded BreedBase (data/BreedBaseGenotypesDownload.vcf)centimorgan-scale genetic map positions reference genome version VCF. Can sourced Cassavabase FTP, FTP archive, another alternative.centimorgan-scale genetic map positions reference genome version VCF. Can sourced Cassavabase FTP, FTP archive, another alternative.Expected outputs:\nparent selection: MAF filtered, dosage matrix, possibly samples removed relative database download.\nmate selection:\nhaplotype matrix extracted VCF\ndosage matrix (computed haplotype matrix)\nfiltered SNP list\nInterpolated genetic map, cM position SNP\n\nparent mate selection: genomic relationship matrices (GRMs, aka kinship matrices), possibly additive dominance relationship matrices, constructed based dosage matrix.\nExpected outputs:parent selection: MAF filtered, dosage matrix, possibly samples removed relative database download.parent selection: MAF filtered, dosage matrix, possibly samples removed relative database download.mate selection:\nhaplotype matrix extracted VCF\ndosage matrix (computed haplotype matrix)\nfiltered SNP list\nInterpolated genetic map, cM position SNP\nmate selection:haplotype matrix extracted VCFa haplotype matrix extracted VCFa dosage matrix (computed haplotype matrix)dosage matrix (computed haplotype matrix)filtered SNP lista filtered SNP listInterpolated genetic map, cM position SNPInterpolated genetic map, cM position SNPFor parent mate selection: genomic relationship matrices (GRMs, aka kinship matrices), possibly additive dominance relationship matrices, constructed based dosage matrix.parent mate selection: genomic relationship matrices (GRMs, aka kinship matrices), possibly additive dominance relationship matrices, constructed based dosage matrix.","code":""},{"path":"prepare-genotypic-data.html","id":"parent-vs.-mate-selection","chapter":"7 Prepare genotypic data","heading":"7.1 Parent vs. Mate Selection?","text":"following sections exemplify genomic mate selection opposed somewhat simpler genomic parent selection pathway along process map. chapter can simplified / mostly avoided parent selection sufficient.","code":""},{"path":"prepare-genotypic-data.html","id":"check-the-vcf","chapter":"7 Prepare genotypic data","heading":"7.2 Check the VCF","text":"Check VCF ‘manually.’number samples sites expected?data phased?FORMAT fields present? minimum, include GT field.column-names FORMAT (sample names) look right / make sense?SNP IDs “ID” field make sense?","code":"vcftools --vcf data/BreedBaseGenotypesDownload.vcf\n# VCFtools - 0.1.16\n# (C) Adam Auton and Anthony Marcketta 2009\n# \n# Parameters as interpreted:\n#   --vcf data/BreedBaseGenotypesDownload.vcf\n# \n# After filtering, kept 1207 out of 1207 Individuals\n# After filtering, kept 61239 out of a possible 61239 Sites\n# Run Time = 16.00 seconds# look at the header of the VCF file\n# print the \"top-left\" corner of the file\ncat data/BreedBaseGenotypesDownload.vcf | head -n50 | cut -c1-100"},{"path":"prepare-genotypic-data.html","id":"subset-vcf","chapter":"7 Prepare genotypic data","heading":"7.3 Subset VCF","text":"may multiple imputed DNA samples corresponding single unique ‘germplasmName.’ matching phenotypic observations downstream analyses, single entry VCF file must chosen per ‘germplasmName.’Remove extraneous samples, .example / tutorial purposes : randomly sample subset number SNPs thousand, quick, local computations.","code":""},{"path":"prepare-genotypic-data.html","id":"remove-duplicate-samples","chapter":"7 Prepare genotypic data","heading":"7.3.1 Remove duplicate samples","text":"Cassavabase returned multiple columns VCF file column-name, multiple tissue_samples per germplasmName.\nprevents using certain tools, e.g. bcftools errors.Manual solution required:Write just column-names VCF disk. ’s one-liner:Read column-names-file R. Exclude first 9 elements standard VCF columns, “germplasmName”Quite duplicates.Next, (1) create unique names sample column VCF file, (2) write “unique_names_for_vcf.txt” disk (3) use replace current sample column names VCF. Finally, (4) subset VCF one unique instance name.First, manipulate names using R.Now command line:bcftools reheader replace sample names VCF unique ones.Now subset VCF single instance “germplasmName” vcftools.","code":"egrep \"^#CHROM\" data/BreedBaseGenotypesDownload.vcf | head -n1 > data/vcf_colnames.txt\n# egrep \"^##SynonymsOfAccessions=\" data/BreedBaseGenotypesDownload.vcf | head -n1 > data/vcf_synonyms.txt\nvcf_sample_names<-readLines(\"data/vcf_colnames.txt\") %>% \n     strsplit(.,\"\\t\") %>% unlist() %>% \n     .[10:length(.)]\n# Check how many sample names are duplicated?\ntable(duplicated(vcf_sample_names))\n#> \n#> FALSE  TRUE \n#>   963   244\n# create unique names for each VCF\nunique_names_for_vcf<-tibble(vcfName=vcf_sample_names) %>% \n     # create an overall index to ensure I can recover the original column order\n     mutate(vcfIndex=1:n()) %>% \n     # now for each vcfName create an sub-index, to distinguish among duplicates\n     group_by(vcfName) %>% \n     # sub-index\n     mutate(vcfNameIndex=1:n(),\n            # For the first (or only) instance of each unique vcfName\n            vcfName_Unique=ifelse(vcfNameIndex==1,\n                                  # return the original name\n                                  vcfName,\n                                  # for all subsequent (duplicate) names, \n                                  #put a unique-ified name by pasting the sub-index\n                                  paste0(vcfName,\".\",vcfNameIndex)))\n# Write the \"unique_names_for_vcf.txt\" to disk\nwrite.table(unique_names_for_vcf$vcfName_Unique,file = \"data/unique_names_for_vcf.txt\",\n            row.names = F, col.names = F, quote = F)\n# Create also a list containing only one instance of each unique name, the first instance \nsubset_unique_names_for_vcf<-unique_names_for_vcf %>% \n     filter(vcfNameIndex==1) %$%\n     vcfName_Unique\n# Write that list to disk for subsetting the VCF downstream\nwrite.table(subset_unique_names_for_vcf,file = \"data/subset_unique_names_for_vcf.txt\",\n            row.names = F, col.names = F, quote = F)# replace sample names in original VCF with unique ones (creates a new VCF)\nbcftools reheader --samples data/unique_names_for_vcf.txt data/BreedBaseGenotypesDownload.vcf > data/BreedBaseGenotypesDownload_1.vcf; \n# overwrite the original VCF with the new  that has unique names\nmv data/BreedBaseGenotypesDownload_1.vcf data/BreedBaseGenotypesDownload.vcf;\n# check that the names are now unique by printing sample list\nbcftools query --list-samples data/BreedBaseGenotypesDownload.vcfvcftools --vcf data/BreedBaseGenotypesDownload.vcf --keep data/subset_unique_names_for_vcf.txt --recode --stdout | bgzip -c > data/BreedBaseGenotypes_subset.vcf.gz\n# uses stdout and bgzip to output a gzipped vcf file; saves disk space!vcftools --gzvcf data/BreedBaseGenotypes_subset.vcf.gz\n#VCFtools - 0.1.16\n#(C) Adam Auton and Anthony Marcketta 2009\n# Parameters as interpreted:\n#   --gzvcf data/BreedBaseGenotypes_subset.vcf.gz\n# \n# Using zlib version: 1.2.11\n# After filtering, kept 963 out of 963 Individuals\n# After filtering, kept 61239 out of a possible 61239 Sites\n# Run Time = 2.00 seconds"},{"path":"prepare-genotypic-data.html","id":"check-genotype-to-phenotype-matches","chapter":"7 Prepare genotypic data","heading":"7.3.2 Check genotype-to-phenotype matches","text":"number unique germplasmName ([cleaned phenos previous step][save_cleaned_phenos]) matching samples VCF make sense? many expected? , need figure .many matches VCF?350 matches.\nmake sense?\nYes. ended excluding “genetic gain” trial phenotypes b/c actually trait scores.sure, look names :\n(1) genotyped phenotyped, (2) genotyped phenotyped, (3) phenotyped genotyped.diagnose phenotyped---genotyped, actually resorted searching Cassavabase verify non-genotyped lines trials downloaded.genotyped---phenotyped, indeed names “genetic gain” population clones.Probably details change go back choose better example trials.checklist approach verifying stay .","code":"\nphenos<-readRDS(here::here(\"output\",\"phenotypes_cleaned.rds\"))\n\n# vector of the unique germplasmName in the field trial data\ngermplasm_with_phenos<-unique(phenos$germplasmName)\nlength(germplasm_with_phenos) \n#> [1] 1002\ntable(germplasm_with_phenos %in% subset_unique_names_for_vcf)\n#> \n#> FALSE  TRUE \n#>   652   350\n# geno and pheno\nsubset_unique_names_for_vcf[subset_unique_names_for_vcf %in% germplasm_with_phenos]\n# pheno not geno\ngermplasm_with_phenos[!germplasm_with_phenos %in% subset_unique_names_for_vcf]\n# geno not pheno\nsubset_unique_names_for_vcf[!subset_unique_names_for_vcf %in% germplasm_with_phenos]"},{"path":"prepare-genotypic-data.html","id":"subset-snps-for-tutorial-purposes","chapter":"7 Prepare genotypic data","heading":"7.3.3 Subset SNPs (for tutorial purposes)","text":"example / tutorial purposes : randomly sample subset number SNPs thousand, quick, local computations.Read R, sample 4000 randomSubset VCF using randomly sampled list positions.","code":"# write the positions list\n# first two columns (chrom. and position) of the VCF \n# ignoring the header rows\ncat data/BreedBaseGenotypesDownload.vcf | grep -v \"^#\" | cut -f1-2 > data/BreedBaseGenotypesDownload.positions\nset.seed(1234)\nread.table(here::here(\"data\",\"BreedBaseGenotypesDownload.positions\"), \n           header = F, stringsAsFactors = F) %>% \n     dplyr::slice_sample(n=4000) %>% \n     arrange(V1,V2) %>% \n     write.table(.,file = \"data/BreedBaseGenotypes_subset.positions\",\n                 row.names = F, col.names = F, quote = F)vcftools --vcf data/BreedBaseGenotypesDownload.vcf \\\n--keep data/subset_unique_names_for_vcf.txt \\\n--positions data/BreedBaseGenotypes_subset.positions \\\n--recode --stdout | bgzip -c > data/BreedBaseGenotypes_subset.vcf.gz\n# VCFtools - 0.1.16\n# (C) Adam Auton and Anthony Marcketta 2009\n# \n# Parameters as interpreted:\n#   --vcf data/BreedBaseGenotypesDownload.vcf\n#   --keep data/subset_unique_names_for_vcf.txt\n#   --positions data/BreedBaseGenotypes_subset.positions\n#   --recode\n#   --stdout\n# \n# Keeping individuals in 'keep' list\n# After filtering, kept 963 out of 1207 Individuals\n# Outputting VCF file...\n# After filtering, kept 4000 out of a possible 61239 Sites\n# Run Time = 8.00 seconds"},{"path":"prepare-genotypic-data.html","id":"ld-prunning-snps-for-computational-savings","chapter":"7 Prepare genotypic data","heading":"7.3.4 LD-prunning SNPs (for computational savings)","text":"DEMONSTRATED , YET. practice, predicting cross-variances, can still computationally intensive large numbers markers. Previously, used plink --indep-pairwise prune markers based linkage disequilibrium. found LD-prunned subset similar accuracy full set, less half markers. Subsequently, used full set predict cross means, LD-pruned marker subset cross variances predictions >250K crosses 719 candidate parents IITA’s 2021 crossing block.","code":""},{"path":"prepare-genotypic-data.html","id":"haplotype-matrix-from-vcf","chapter":"7 Prepare genotypic data","heading":"7.4 Haplotype matrix from VCF","text":"Extract haplotypes VCF bcftools convert --hapsampleRead haps R format .Add sample ID’s.Format, transpose, convert matrix.","code":"bcftools convert --hapsample data/BreedBaseGenotypes_subset data/BreedBaseGenotypes_subset.vcf.gz\n# Hap file: data/BreedBaseGenotypes_subset.hap.gz\n# Sample file: data/BreedBaseGenotypes_subset.samples\n# [W::vcf_parse_format] FORMAT 'NT' at 1:652699 is not defined in the header, assuming Type=String\n# 4000 records written, 0 skipped: 0/0/0 no-ALT/non-biallelic/filtered\nlibrary(data.table)\n#> \n#> Attaching package: 'data.table'\n#> The following objects are masked from 'package:dplyr':\n#> \n#>     between, first, last\n#> The following object is masked from 'package:purrr':\n#> \n#>     transpose\nvcfName<-\"BreedBaseGenotypes_subset\"\nhaps<-fread(paste0(\"data/\",vcfName,\".hap.gz\"),\n            stringsAsFactors = F,header = F) %>% \n  as.data.frame\nsampleids<-fread(paste0(\"data/\",vcfName,\".samples\"),\n                 stringsAsFactors = F,header = F,skip = 2) %>% \n  as.data.frame\nhapids<-sampleids %>% \n     select(V1,V2) %>% \n     mutate(SampleIndex=1:nrow(.)) %>% \n     rename(HapA=V1,HapB=V2) %>% \n     pivot_longer(cols=c(HapA,HapB),\n                  names_to = \"Haplo\",values_to = \"SampleID\") %>% \n     mutate(HapID=paste0(SampleID,\"_\",Haplo)) %>% \n     arrange(SampleIndex)\ncolnames(haps)<-c(\"Chr\",\"HAP_ID\",\"Pos\",\"REF\",\"ALT\",hapids$HapID)\ndim(haps)\n#> [1] 4000 1931\nhaps %<>% \n     mutate(HAP_ID=gsub(\":\",\"_\",HAP_ID)) %>% \n     column_to_rownames(var = \"HAP_ID\") %>% \n     select(-Chr,-Pos,-REF,-ALT) %>% \n     t(.) %>% \n     as.matrix(.)"},{"path":"prepare-genotypic-data.html","id":"dosage-matrix-from-haps","chapter":"7 Prepare genotypic data","heading":"7.5 Dosage matrix from haps","text":"ensure consistency allele counting, create dosage haps manually.counted allele dosage matrix, used downstream construct kinship matrices estimate marker effects, ALT allele. ensure match haplotype matrix, “1” indicates presence ALT allele.’s tidyverse-based approach, using group_by() plus summarise() sum two haplotypes individual across loci.","code":"\ndosages<-haps %>%\n     as.data.frame(.) %>% \n     rownames_to_column(var = \"GID\") %>% \n     separate(GID,c(\"SampleID\",\"Haplo\"),\"_Hap\",remove = T) %>% \n     select(-Haplo) %>% \n     group_by(SampleID) %>% \n     summarise(across(everything(),~sum(.))) %>% \n     ungroup() %>% \n     column_to_rownames(var = \"SampleID\") %>% \n     as.matrix %>% \n     # preserve same order as in haps\n     .[sampleids$V1,]\ndim(dosages)\n#> [1]  963 4000\n# [1]  963 4000\n\ndosages[1:5,1:5]\n#>                    1_652699_G_C 1_868970_G_T 1_943129_T_A\n#> IITA-TMS-IBA30572             1            0            0\n#> IITA-TMS-IBA940237            0            0            1\n#> IITA-TMS-IBA961642            1            1            0\n#> IITA-TMS-ONN920168            0            0            0\n#> IITA-TMS-WAR4080              1            0            0\n#>                    1_1132830_A_T 1_1310706_A_T\n#> IITA-TMS-IBA30572              1             0\n#> IITA-TMS-IBA940237             1             1\n#> IITA-TMS-IBA961642             2             0\n#> IITA-TMS-ONN920168             0             0\n#> IITA-TMS-WAR4080               1             0\nhaps[1:10,1:5]\n#>                         1_652699_G_C 1_868970_G_T\n#> IITA-TMS-IBA30572_HapA             1            0\n#> IITA-TMS-IBA30572_HapB             0            0\n#> IITA-TMS-IBA940237_HapA            0            0\n#> IITA-TMS-IBA940237_HapB            0            0\n#> IITA-TMS-IBA961642_HapA            1            0\n#> IITA-TMS-IBA961642_HapB            0            1\n#> IITA-TMS-ONN920168_HapA            0            0\n#> IITA-TMS-ONN920168_HapB            0            0\n#> IITA-TMS-WAR4080_HapA              0            0\n#> IITA-TMS-WAR4080_HapB              1            0\n#>                         1_943129_T_A 1_1132830_A_T\n#> IITA-TMS-IBA30572_HapA             0             1\n#> IITA-TMS-IBA30572_HapB             0             0\n#> IITA-TMS-IBA940237_HapA            0             0\n#> IITA-TMS-IBA940237_HapB            1             1\n#> IITA-TMS-IBA961642_HapA            0             1\n#> IITA-TMS-IBA961642_HapB            0             1\n#> IITA-TMS-ONN920168_HapA            0             0\n#> IITA-TMS-ONN920168_HapB            0             0\n#> IITA-TMS-WAR4080_HapA              0             0\n#> IITA-TMS-WAR4080_HapB              0             1\n#>                         1_1310706_A_T\n#> IITA-TMS-IBA30572_HapA              0\n#> IITA-TMS-IBA30572_HapB              0\n#> IITA-TMS-IBA940237_HapA             0\n#> IITA-TMS-IBA940237_HapB             1\n#> IITA-TMS-IBA961642_HapA             0\n#> IITA-TMS-IBA961642_HapB             0\n#> IITA-TMS-ONN920168_HapA             0\n#> IITA-TMS-ONN920168_HapB             0\n#> IITA-TMS-WAR4080_HapA               0\n#> IITA-TMS-WAR4080_HapB               0"},{"path":"prepare-genotypic-data.html","id":"variant-filters","chapter":"7 Prepare genotypic data","heading":"7.6 Variant filters","text":"case, simple: keep positions >1% minor allele frequency.","code":"\n# use function built into genomicMateSelectR\ndosages<-maf_filter(dosages,thresh = 0.01)\ndim(dosages)\n#> [1]  963 3986\n# subset haps to match\nhaps<-haps[,colnames(dosages)]"},{"path":"prepare-genotypic-data.html","id":"save-dosages-and-haps","chapter":"7 Prepare genotypic data","heading":"7.6.1 Save dosages and haps","text":"","code":"\nsaveRDS(dosages,file=here::here(\"data\",\"dosages.rds\"))\nsaveRDS(haps,file=here::here(\"data\",\"haplotypes.rds\"))"},{"path":"prepare-genotypic-data.html","id":"genomic-relationship-matrices-grms","chapter":"7 Prepare genotypic data","heading":"7.7 Genomic Relationship Matrices (GRMs)","text":"example , use genomicMateSelectR function kinship() construct additive () dominance (D) relationship matrices.information models --implemented downstream, see vignette genomicMateSelectR, references cited therein.","code":"\nA<-kinship(dosages,type=\"add\")\nD<-kinship(dosages,type=\"domGenotypic\")\nsaveRDS(A,file=here::here(\"output\",\"kinship_add.rds\"))\nsaveRDS(D,file=here::here(\"output\",\"kinship_dom.rds\"))"},{"path":"prepare-genotypic-data.html","id":"recombination-frequency-matrix","chapter":"7 Prepare genotypic data","heading":"7.8 Recombination Frequency Matrix","text":"Matrix need cross-variance predictions.","code":""},{"path":"prepare-genotypic-data.html","id":"source-a-genetic-map","chapter":"7 Prepare genotypic data","heading":"7.8.1 Source a genetic map","text":"Must match reference genome marker set used predictionNot necessarily exact markerset, overlap idealI source single genome-wide file representing ICGMC concensus genetic map V6 Cassava Reference genome. file Cassavabase FTP-archive, .120K positions.","code":"\ngenmap<-read.table(\"https://cassavabase.org/ftp/marnin_datasets/NGC_BigData/CassavaGeneticMap/cassava_cM_pred.v6.allchr.txt\",\n                   header = F, sep=';', stringsAsFactors = F) %>% \n     rename(SNP_ID=V1,Pos=V2,cM=V3) %>% \n  as_tibble\ngenmap %>% dim\n#> [1] 120979      3\ngenmap %>% head\n#> # A tibble: 6 × 3\n#>   SNP_ID     Pos    cM\n#>   <chr>    <int> <dbl>\n#> 1 S1_26576 26576   2.7\n#> 2 S1_26624 26624   2.7\n#> 3 S1_26659 26659   2.7\n#> 4 S1_27720 27720   2.7\n#> 5 S1_27739 27739   2.7\n#> 6 S1_27746 27746   2.7\nsnps_genmap<-tibble(DoseSNP_ID=colnames(dosages)) %>% \n     separate(DoseSNP_ID,c(\"Chr\",\"Pos\",\"Ref\",\"Alt\"),remove = F) %>% \n     mutate(SNP_ID=paste0(\"S\",Chr,\"_\",Pos)) %>% \n     full_join(genmap %>% \n                    separate(SNP_ID,c(\"Chr\",\"POS\"),\"_\",remove = F) %>% \n                    select(-POS) %>% \n                    mutate(Chr=gsub(\"S\",\"\",Chr)) %>% \n                    mutate(across(everything(),as.character)))\n#> Joining, by = c(\"Chr\", \"Pos\", \"SNP_ID\")\nsnps_genmap %>% \n  ggplot(.,aes(x=as.integer(Pos)/1000/1000,y=as.numeric(cM))) +\n  geom_point() +\n  theme_bw() +\n  facet_wrap(~as.integer(Chr))\n#> Warning: Removed 1567 rows containing missing values\n#> (geom_point)."},{"path":"prepare-genotypic-data.html","id":"interpolate-genetic-map","chapter":"7 Prepare genotypic data","heading":"7.8.2 Interpolate genetic map","text":"","code":"\ninterpolate_genmap<-function(data){\n  # for each chromosome map\n  # find and _decrements_ in the genetic map distance\n  # fix them to the cumulative max to force map to be only increasing\n  # fit a spline for each chromosome\n  # Use it to predict values for positions not previously on the map\n  # fix them AGAIN (in case) to the cumulative max, forcing map to only increase\n  data_forspline<-data %>% \n    filter(!is.na(cM)) %>% \n    mutate(cumMax=cummax(cM),\n           cumIncrement=cM-cumMax) %>% \n    filter(cumIncrement>=0) %>% \n    select(-cumMax,-cumIncrement)\n  \n  spline<-data_forspline %$% smooth.spline(x=Pos,y=cM,spar = 0.75)\n  \n  splinemap<-predict(spline,x = data$Pos) %>% \n    as_tibble(.) %>% \n    rename(Pos=x,cM=y) %>% \n    mutate(cumMax=cummax(cM),\n           cumIncrement=cM-cumMax) %>% \n    mutate(cM=cumMax) %>% \n    select(-cumMax,-cumIncrement)\n  \n  return(splinemap) \n}\nsplined_snps_genmap<-snps_genmap %>% \n  select(-cM) %>% \n  mutate(Pos=as.numeric(Pos)) %>% \n  left_join(snps_genmap %>% \n              mutate(across(c(Pos,cM),as.numeric)) %>% \n              arrange(Chr,Pos) %>% \n              nest(-Chr) %>% \n              mutate(data=map(data,interpolate_genmap)) %>% \n              unnest(data)) %>% \n  distinct\n#> Warning: All elements of `...` must be named.\n#> Did you want `data = c(DoseSNP_ID, Pos, Ref, Alt, SNP_ID, cM)`?\n#> Joining, by = c(\"Chr\", \"Pos\")\nall(colnames(dosages) %in% splined_snps_genmap$DoseSNP_ID)\n#> [1] TRUE\nsplined_snps_genmap %>% \n     filter(DoseSNP_ID %in% colnames(dosages)) %>% \n     mutate(Map=\"Spline\") %>% \n     bind_rows(snps_genmap %>% \n                    filter(DoseSNP_ID %in% colnames(dosages),\n                           !is.na(cM)) %>% \n                    mutate(across(c(Pos,cM),as.numeric)) %>% \n                    arrange(Chr,Pos) %>% mutate(Map=\"Data\")) %>% \n  ggplot(.,aes(x=Pos/1000/1000,y=cM,color=Map, shape=Map),alpha=0.3,size=0.75) + \n  geom_point() + \n  theme_bw() + facet_wrap(~as.integer(Chr), scales='free_x')\nsplined_snps_genmap %>% \n     filter(DoseSNP_ID %in% colnames(dosages)) %>% \n     saveRDS(.,file=here::here(\"output\",\"interpolated_genmap.rds\"))"},{"path":"prepare-genotypic-data.html","id":"recomb.-freq.-matrix","chapter":"7 Prepare genotypic data","heading":"7.8.3 Recomb. freq. matrix","text":"See also, genomicMateSelectR vignette.","code":"\ngenmap<-readRDS(file=here::here(\"output\",\"interpolated_genmap.rds\"))\nm<-genmap$cM;\nnames(m)<-genmap$DoseSNP_ID\nrecombFreqMat<-1-(2*genmap2recombfreq(m,nChr = 18))\nsaveRDS(recombFreqMat,file=here::here(\"output\",\"recombFreqMat_1minus2c.rds\"))"},{"path":"preliminary-field-trial-analysis.html","id":"preliminary-field-trial-analysis","chapter":"8 Preliminary field trial analysis","heading":"8 Preliminary field trial analysis","text":"Context Purpose:Context Purpose:Upstream: Section 7 - quality control steps genotypic dataUpstream: Section 7 - quality control steps genotypic dataDownstream: Genomic prediction related analyses.Downstream: Genomic prediction related analyses.Inputs:Inputs:Expected outputs:Expected outputs:","code":""},{"path":"preliminary-field-trial-analysis.html","id":"one-stage-or-multi-stage","chapter":"8 Preliminary field trial analysis","heading":"8.1 One-stage or multi-stage?","text":"often large, multi-year, multi-location, multi-trial-type (MET) datasets use train genomic prediction models. number plots can range 10- even 100,000 plots many thousands unique genotypes observed unbalanced fashion across heterogenous experimental designs. say, computational burden level expertise required execute genomic prediction analyses directly data great.sake semi-automation computational efficiency, standard genomic prediction pipeline implemented NextGen Cassava, demonstrate , two stages:Stage 1. Get BLUPsConduct preliminary analysis trial data without genomic relatedeness / marker-information.\nIdentify best-fitting model data potentially curate raw data, removing outliers.Conduct preliminary analysis trial data without genomic relatedeness / marker-information.Identify best-fitting model data potentially curate raw data, removing outliers.Fit mixed-model MET data. Extract BLUPs, PEVs variance components (VarComps). Compute de-regressed BLUPs (drgBLUPs) weights (WTS) “Stage 2.”Fit mixed-model MET data. Extract BLUPs, PEVs variance components (VarComps). Compute de-regressed BLUPs (drgBLUPs) weights (WTS) “Stage 2.”Stage 2. Cross-validation genomic predictionConduct weighted cross-validation genomic prediction analyses using de-regressed BLUPs (alternative BLUEs) response variable weights Stage 1. effectively reduces number “observations” analysis number unique genotypes (.e. clones, inbred lines, etc.), leading lower computational burden.Note advice single-stage analyses: strongly recommend conducting preliminary analysis trial data without genomic relatedeness / marker-information. Ensure model converge, residuals look acceptable otherwise assess best fitting model commiting lengthy computationally intensive analyses. :)","code":""},{"path":"preliminary-field-trial-analysis.html","id":"set-up-training-datasets","chapter":"8 Preliminary field trial analysis","heading":"8.2 Set-up training datasets","text":"pipeline version analysis use TRUE/FALSE values CompleteBlocks IncompleteBlocks ([Preliminary analysis trial data][#detect_designs]).","code":"\nphenos<-readRDS(here::here(\"output\",\"phenotypes_cleaned.rds\"))\nphenos %>% \n     count(CompleteBlocks,IncompleteBlocks,locationName) %>% \n     spread(locationName,n)\n#> # A tibble: 3 × 4\n#>   CompleteBlocks IncompleteBlocks Ibadan Ubiaja\n#>   <lgl>          <lgl>             <int>  <int>\n#> 1 FALSE          TRUE                777     NA\n#> 2 TRUE           FALSE                NA    125\n#> 3 TRUE           TRUE                407    414\n#traits<-c(\"\")\nnestDesignsDetectedByTraits\n#> function(indata,traits){\n#>   indata %<>%\n#>     select(programName,locationName,studyYear,TrialType,studyName,\n#>            CompleteBlocks,IncompleteBlocks,\n#>            yearInLoc,trialInLocYr,repInTrial,blockInRep,observationUnitDbId,\n#>            germplasmName,FullSampleName,GID,all_of(traits),PropNOHAV) %>%\n#>     mutate(IncompleteBlocks=ifelse(IncompleteBlocks==TRUE,\"Yes\",\"No\"),\n#>            CompleteBlocks=ifelse(CompleteBlocks==TRUE,\"Yes\",\"No\")) %>%\n#>     pivot_longer(cols = all_of(traits), names_to = \"Trait\", values_to = \"Value\") %>%\n#>     filter(!is.na(Value),\n#>            !is.na(GID)) %>%\n#>     nest(MultiTrialTraitData=c(-Trait))\n#>   return(indata)\n#> }\n#> <bytecode: 0x7ff418cf2110>\n#> <environment: namespace:genomicMateSelectR>"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
